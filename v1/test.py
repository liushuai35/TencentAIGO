"""
ä¼˜åŒ–ç‰ˆæ¨¡å‹æµ‹è¯•è„šæœ¬

ç”¨äºæµ‹è¯•ä¼˜åŒ–åçš„ä»£ç æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œï¼ŒåŒ…æ‹¬ï¼š
1. å¯¼å…¥æµ‹è¯•
2. æ•°æ®å¤„ç†æµ‹è¯•
3. æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•
4. è®­ç»ƒæµç¨‹æµ‹è¯•
"""

import os
import sys
import tempfile
import json
import pickle
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.test_results = []
    
    def run_test(self, test_name: str, test_func):
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        try:
            logger.info(f"Running test: {test_name}")
            test_func()
            self.test_results.append((test_name, "PASSED", None))
            logger.info(f"âœ“ {test_name} PASSED")
        except Exception as e:
            self.test_results.append((test_name, "FAILED", str(e)))
            logger.error(f"âœ— {test_name} FAILED: {e}")
    
    def print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\\n" + "="*60)
        print("TEST RESULTS")
        print("="*60)
        
        passed = sum(1 for _, status, _ in self.test_results if status == "PASSED")
        total = len(self.test_results)
        
        for test_name, status, error in self.test_results:
            status_symbol = "âœ“" if status == "PASSED" else "âœ—"
            print(f"{status_symbol} {test_name}: {status}")
            if error:
                print(f"  Error: {error}")
        
        print(f"\\nSummary: {passed}/{total} tests passed")
        print("="*60)
        
        return passed == total


def test_imports():
    """æµ‹è¯•å¯¼å…¥"""
    try:
        import torch
        import numpy as np
        from tqdm import tqdm
        logger.info(f"PyTorch version: {torch.__version__}")
        logger.info(f"NumPy version: {np.__version__}")
        logger.info("All imports successful")
    except ImportError as e:
        raise ImportError(f"Import failed: {e}")


def test_dataset_creation():
    """æµ‹è¯•æ•°æ®é›†åˆ›å»º"""
    # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°
    class MockArgs:
        maxlen = 10
        mm_emb_id = ['81']
        device = 'cpu'
    
    # åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•å’Œæ–‡ä»¶
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®æ–‡ä»¶
        seq_file = temp_path / "seq.jsonl"
        with open(seq_file, 'w') as f:
            # å†™å…¥æ¨¡æ‹Ÿåºåˆ—æ•°æ®
            sample_data = [
                [1, 100, {}, {"feature1": 1}, 1, 1234567890],
                [1, 101, {}, {"feature1": 2}, 1, 1234567891]
            ]
            f.write(json.dumps(sample_data) + '\\n')
        
        # åˆ›å»ºåç§»æ–‡ä»¶
        offset_file = temp_path / "seq_offsets.pkl"
        with open(offset_file, 'wb') as f:
            pickle.dump({0: 0}, f)
        
        # åˆ›å»ºç´¢å¼•å™¨æ–‡ä»¶
        indexer_file = temp_path / "indexer.pkl"
        indexer = {
            'i': {100: 1, 101: 2},
            'u': {1: 1}
        }
        with open(indexer_file, 'wb') as f:
            pickle.dump(indexer, f)
        
        # åˆ›å»ºç‰©å“ç‰¹å¾æ–‡ä»¶
        item_feat_file = temp_path / "item_feat_dict.json"
        with open(item_feat_file, 'w') as f:
            json.dump({"100": {"feature1": 1}, "101": {"feature1": 2}}, f)
        
        # åˆ›å»ºå¤šæ¨¡æ€ç‰¹å¾ç›®å½•
        mm_dir = temp_path / "creative_emb"
        mm_dir.mkdir()
        
        # æµ‹è¯•æ•°æ®é›†åˆå§‹åŒ–
        from dataset import OptimizedDataset
        
        args = MockArgs()
        dataset = OptimizedDataset(str(temp_path), args)
        
        logger.info(f"Dataset created with {len(dataset)} samples")
        
        # æµ‹è¯•è·å–æ ·æœ¬
        if len(dataset) > 0:
            sample = dataset[0]
            logger.info(f"Sample shape: {len(sample)} components")


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    try:
        import torch
        
        # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°
        class MockArgs:
            hidden_units = 32
            num_blocks = 1
            num_heads = 1
            dropout_rate = 0.1
            norm_first = True
            device = 'cpu'
            maxlen = 10
        
        from model import OptimizedBaselineModel
        
        # æ¨¡æ‹Ÿç‰¹å¾ç»Ÿè®¡å’Œç±»å‹
        feat_statistics = {'81': 32}
        feat_types = {
            'user_sparse': [],
            'user_continual': [],
            'user_array': [],
            'item_sparse': [],
            'item_continual': [],
            'item_array': [],
            'item_emb': ['81']
        }
        
        args = MockArgs()
        model = OptimizedBaselineModel(
            user_num=100,
            item_num=1000,
            feat_statistics=feat_statistics,
            feat_types=feat_types,
            args=args
        )
        
        # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
        batch_size = 2
        seq_len = 10
        
        # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
        seq = torch.randint(1, 100, (batch_size, seq_len))
        pos = torch.randint(1, 100, (batch_size, seq_len))
        neg = torch.randint(1, 100, (batch_size, seq_len))
        mask = torch.ones(batch_size, seq_len, dtype=torch.long)
        next_mask = torch.ones(batch_size, seq_len, dtype=torch.long)
        next_action = torch.ones(batch_size, seq_len, dtype=torch.long)
        
        # æ¨¡æ‹Ÿç‰¹å¾
        seq_features = [[{} for _ in range(seq_len)] for _ in range(batch_size)]
        pos_features = [[{} for _ in range(seq_len)] for _ in range(batch_size)]
        neg_features = [[{} for _ in range(seq_len)] for _ in range(batch_size)]
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            pos_logits, neg_logits = model(
                seq, pos, neg, mask, next_mask, next_action,
                seq_features, pos_features, neg_features
            )
        
        logger.info(f"Model forward pass successful: {pos_logits.shape}, {neg_logits.shape}")
        
    except Exception as e:
        raise RuntimeError(f"Model creation failed: {e}")


def test_training_setup():
    """æµ‹è¯•è®­ç»ƒè®¾ç½®"""
    try:
        import torch
        import torch.nn as nn
        from torch.utils.data import DataLoader
        
        # åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒç»„ä»¶
        model = torch.nn.Linear(10, 1)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.BCEWithLogitsLoss()
        
        # æµ‹è¯•ç®€å•çš„å‰å‘å’Œåå‘ä¼ æ’­
        x = torch.randn(5, 10)
        y = torch.randn(5, 1)
        
        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, torch.sigmoid(y))
        loss.backward()
        optimizer.step()
        
        logger.info(f"Training setup test successful, loss: {loss.item()}")
        
    except Exception as e:
        raise RuntimeError(f"Training setup failed: {e}")


def test_configuration_loading():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    config_file = Path(__file__).parent / "config.yaml"
    
    if config_file.exists():
        try:
            import yaml
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
            logger.info("Configuration file loaded successfully")
            logger.info(f"Model config: {config.get('model', {})}")
        except ImportError:
            logger.warning("PyYAML not installed, skipping YAML config test")
            # ç®€å•çš„æ–‡æœ¬è§£ææµ‹è¯•
            with open(config_file, 'r') as f:
                content = f.read()
            logger.info("Configuration file exists and readable")
    else:
        raise FileNotFoundError("Configuration file not found")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("OPTIMIZED GENERATIVE RECOMMENDATION SYSTEM TESTS")
    print("="*60)
    
    runner = TestRunner()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    runner.run_test("Import Test", test_imports)
    runner.run_test("Dataset Creation Test", test_dataset_creation)
    runner.run_test("Model Creation Test", test_model_creation)
    runner.run_test("Training Setup Test", test_training_setup)
    runner.run_test("Configuration Loading Test", test_configuration_loading)
    
    # æ‰“å°ç»“æœ
    all_passed = runner.print_results()
    
    if all_passed:
        print("\\nğŸ‰ All tests passed! The optimized system is ready to use.")
    else:
        print("\\nâš ï¸  Some tests failed. Please check the errors above.")
        sys.exit(1)


if __name__ == "__main__":
    main()
