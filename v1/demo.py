"""
æ¼”ç¤ºè„šæœ¬ - ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•å®Œæ•´çš„è®­ç»ƒæµç¨‹

è¿™ä¸ªè„šæœ¬åˆ›å»ºæ¨¡æ‹Ÿçš„æ¨èç³»ç»Ÿæ•°æ®ï¼Œå¹¶è¿è¡Œä¸€ä¸ªå°è§„æ¨¡çš„è®­ç»ƒæ¥éªŒè¯æ•´ä¸ªæµç¨‹
"""

import os
import json
import pickle
import tempfile
from pathlib import Path
import numpy as np
import torch
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_mock_data(data_dir: Path, num_users: int = 10, num_items: int = 100, seq_length: int = 20):
    """
    åˆ›å»ºæ¨¡æ‹Ÿçš„æ¨èç³»ç»Ÿæ•°æ®
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        num_users: ç”¨æˆ·æ•°é‡
        num_items: ç‰©å“æ•°é‡
        seq_length: åºåˆ—é•¿åº¦
    """
    logger.info(f"Creating mock data in {data_dir}")
    
    # åˆ›å»ºç”¨æˆ·åºåˆ—æ•°æ®
    sequences = []
    seq_offsets = {}
    
    for user_id in range(1, num_users + 1):
        user_seq = []
        for i in range(seq_length):
            item_id = np.random.randint(1, num_items + 1)
            user_feat = {"age": np.random.randint(18, 65), "gender": np.random.randint(0, 2)}
            item_feat = {"category": np.random.randint(1, 10), "price": np.random.uniform(10, 1000)}
            action_type = np.random.randint(0, 2)  # 0: view, 1: click
            timestamp = 1600000000 + i * 3600  # Mock timestamp
            
            user_seq.append([user_id, item_id, user_feat, item_feat, action_type, timestamp])
        
        sequences.append(user_seq)
    
    # ä¿å­˜åºåˆ—æ•°æ®
    with open(data_dir / "seq.jsonl", 'w') as f:
        offset = 0
        for i, seq in enumerate(sequences):
            seq_offsets[i] = offset
            line = json.dumps(seq) + '\\n'
            f.write(line)
            offset += len(line.encode('utf-8'))
    
    # ä¿å­˜åç§»é‡
    with open(data_dir / "seq_offsets.pkl", 'wb') as f:
        pickle.dump(seq_offsets, f)
    
    # åˆ›å»ºç´¢å¼•å™¨
    indexer = {
        'i': {item_id: item_id for item_id in range(1, num_items + 1)},
        'u': {user_id: user_id for user_id in range(1, num_users + 1)}
    }
    with open(data_dir / "indexer.pkl", 'wb') as f:
        pickle.dump(indexer, f)
    
    # åˆ›å»ºç‰©å“ç‰¹å¾å­—å…¸
    item_feat_dict = {}
    for item_id in range(1, num_items + 1):
        item_feat_dict[str(item_id)] = {
            "category": np.random.randint(1, 10),
            "price": float(np.random.uniform(10, 1000)),
            "brand": np.random.randint(1, 20)
        }
    
    with open(data_dir / "item_feat_dict.json", 'w') as f:
        json.dump(item_feat_dict, f)
    
    # åˆ›å»ºå¤šæ¨¡æ€ç‰¹å¾ç›®å½•ï¼ˆå¯é€‰ï¼‰
    mm_dir = data_dir / "creative_emb"
    mm_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„å¤šæ¨¡æ€ç‰¹å¾ï¼ˆè¿™é‡Œåˆ›å»ºç©ºçš„ï¼Œå› ä¸ºæµ‹è¯•ä¸­æˆ‘ä»¬å¯èƒ½ä¸éœ€è¦ï¼‰
    mock_mm_features = {}
    for item_id in range(1, min(num_items + 1, 50)):  # åªä¸ºå‰50ä¸ªç‰©å“åˆ›å»ºç‰¹å¾
        mock_mm_features[str(item_id)] = np.random.randn(32).tolist()  # 32ç»´ç‰¹å¾
    
    np.save(mm_dir / "81.npy", mock_mm_features)
    
    logger.info(f"Mock data created: {num_users} users, {num_items} items")


def run_demo_training():
    """è¿è¡Œæ¼”ç¤ºè®­ç»ƒ"""
    logger.info("Starting demo training with mock data")
    
    # åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        data_path = Path(temp_dir)
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        create_mock_data(data_path, num_users=5, num_items=20, seq_length=10)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['TRAIN_DATA_PATH'] = str(data_path)
        os.environ['TRAIN_LOG_PATH'] = str(data_path / 'logs')
        os.environ['TRAIN_TF_EVENTS_PATH'] = str(data_path / 'tb_logs')
        
        # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°
        class MockArgs:
            # æ•°æ®å‚æ•°
            batch_size = 2
            maxlen = 8
            num_workers = 0
            
            # æ¨¡å‹å‚æ•°
            hidden_units = 16
            num_blocks = 1
            num_heads = 1
            dropout_rate = 0.1
            norm_first = True
            
            # è®­ç»ƒå‚æ•°
            num_epochs = 2
            lr = 0.01
            optimizer = 'adam'
            weight_decay = 0.01
            lr_scheduler = 'none'
            grad_clip = 1.0
            l2_emb = 0.0
            
            # ç³»ç»Ÿå‚æ•°
            device = 'cpu'  # ä½¿ç”¨CPUé¿å…CUDAé—®é¢˜
            seed = 42
            save_freq = 1
            
            # å…¶ä»–å‚æ•°
            state_dict_path = None
            inference_only = False
            mm_emb_id = ['81']
        
        try:
            # å¯¼å…¥è®­ç»ƒæ¨¡å—
            from dataset import OptimizedDataset
            from model import OptimizedBaselineModel
            from main import ModelTrainer
            
            args = MockArgs()
            
            # æµ‹è¯•æ•°æ®é›†åŠ è½½
            logger.info("Testing dataset loading...")
            dataset = OptimizedDataset(str(data_path), args)
            logger.info(f"Dataset loaded: {len(dataset)} samples")
            
            # æµ‹è¯•æ¨¡å‹åˆ›å»º
            logger.info("Testing model creation...")
            model = OptimizedBaselineModel(
                user_num=dataset.usernum,
                item_num=dataset.itemnum,
                feat_statistics=dataset.feat_statistics,
                feat_types=dataset.feature_types,
                args=args
            )
            logger.info(f"Model created with {sum(p.numel() for p in model.parameters())} parameters")
            
            # æµ‹è¯•è®­ç»ƒå™¨
            logger.info("Testing trainer initialization...")
            trainer = ModelTrainer(args)
            logger.info("Trainer initialized successfully")
            
            # è¿è¡Œä¸€ä¸ªçŸ­çš„è®­ç»ƒ
            logger.info("Running short training demo...")
            trainer.train()
            
            logger.info("âœ“ Demo training completed successfully!")
            return True
            
        except Exception as e:
            logger.error(f"Demo training failed: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("DEMO TRAINING WITH MOCK DATA")
    print("=" * 60)
    
    try:
        success = run_demo_training()
        
        if success:
            print("\\nğŸ‰ Demo training completed successfully!")
            print("\\nThe optimized generative recommendation system is working correctly.")
            print("\\nTo use with real data:")
            print("1. Prepare your data in the required format")
            print("2. Set the TRAIN_DATA_PATH environment variable")
            print("3. Run: python main.py with your desired parameters")
        else:
            print("\\nâš ï¸ Demo training failed. Please check the logs above.")
            return False
            
    except Exception as e:
        print(f"\\nâŒ Demo failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    import sys
    success = main()
    sys.exit(0 if success else 1)
